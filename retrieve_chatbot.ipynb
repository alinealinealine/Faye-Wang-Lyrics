{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.llms import OpenAI\n",
    "# from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Title</th>\n",
       "      <th>Album Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://mojim.com/cny100019x82x1.htm</td>\n",
       "      <td>\\n王菲\\n\\n\\n\\n\\n\\n\\n归途有风\\n\\n\\n电影 万里归途 主题曲\\n作词：唐恬...</td>\n",
       "      <td>归途有风</td>\n",
       "      <td>归途有风</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://mojim.com/cny100019x81x1.htm</td>\n",
       "      <td>\\n王菲\\n\\n\\n\\n\\n\\n\\n如愿\\n\\n\\n作词：唐恬\\n作曲：钱雷\\n你是 遥遥的...</td>\n",
       "      <td>如愿</td>\n",
       "      <td>如愿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://mojim.com/cny100019x79x1.htm</td>\n",
       "      <td>\\n王菲\\n\\n\\n\\n\\n\\n\\n偶遇\\n\\n\\n电影 邪不压正 宣传曲\\n作词：林珺帆\\...</td>\n",
       "      <td>偶遇</td>\n",
       "      <td>电影 邪不压正</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://mojim.com/cny100019x77x1.htm</td>\n",
       "      <td>\\n王菲\\n\\n\\n\\n\\n\\n\\n无问西东\\n\\n\\n作词：彭青\\n作曲：彭青\\n编曲：彭...</td>\n",
       "      <td>无问西东</td>\n",
       "      <td>电影《无问西东》推广曲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://mojim.com/cny100019x75x1.htm</td>\n",
       "      <td>\\n王菲\\n\\n\\n\\n\\n\\n\\n你在终点等我\\n\\n\\n作词：姚若龙\\n作曲：陈小霞\\n...</td>\n",
       "      <td>你在终点等我</td>\n",
       "      <td>电影《从你的全世界路过》片尾曲</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    URL  \\\n",
       "0  https://mojim.com/cny100019x82x1.htm   \n",
       "1  https://mojim.com/cny100019x81x1.htm   \n",
       "2  https://mojim.com/cny100019x79x1.htm   \n",
       "3  https://mojim.com/cny100019x77x1.htm   \n",
       "4  https://mojim.com/cny100019x75x1.htm   \n",
       "\n",
       "                                              Lyrics   Title      Album Title  \n",
       "0  \\n王菲\\n\\n\\n\\n\\n\\n\\n归途有风\\n\\n\\n电影 万里归途 主题曲\\n作词：唐恬...    归途有风             归途有风  \n",
       "1  \\n王菲\\n\\n\\n\\n\\n\\n\\n如愿\\n\\n\\n作词：唐恬\\n作曲：钱雷\\n你是 遥遥的...      如愿               如愿  \n",
       "2  \\n王菲\\n\\n\\n\\n\\n\\n\\n偶遇\\n\\n\\n电影 邪不压正 宣传曲\\n作词：林珺帆\\...      偶遇          电影 邪不压正  \n",
       "3  \\n王菲\\n\\n\\n\\n\\n\\n\\n无问西东\\n\\n\\n作词：彭青\\n作曲：彭青\\n编曲：彭...    无问西东      电影《无问西东》推广曲  \n",
       "4  \\n王菲\\n\\n\\n\\n\\n\\n\\n你在终点等我\\n\\n\\n作词：姚若龙\\n作曲：陈小霞\\n...  你在终点等我  电影《从你的全世界路过》片尾曲  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.read_csv(\"lyrics_wf.csv\")\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# define the regular expression pattern to match the timestamps\n",
    "pattern = r\"\\[\\d{2}:\\d{2}\\.\\d{2}\\]\"\n",
    "\n",
    "# use the re.sub() function to remove the timestamps from the text\n",
    "tmp['Lyrics'] = tmp['Lyrics'].apply(lambda x: re.sub(pattern, \"\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. One row per line\n",
    "- notes: not a sentence, only return word phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.replace(r\"\\n{2,}\", \"\\n\", regex=True, inplace=True)\n",
    "new = tmp.assign(lyrics = tmp['Lyrics'].str.split(\"\\n\")).explode('lyrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Specify minimal chunk size, merge the subsequent chunks when too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Title Album                                    URL  \\\n",
      "0       归途有风  归途有风   https://mojim.com/cny100019x82x1.htm   \n",
      "1       归途有风  归途有风   https://mojim.com/cny100019x82x1.htm   \n",
      "2       归途有风  归途有风   https://mojim.com/cny100019x82x1.htm   \n",
      "3       归途有风  归途有风   https://mojim.com/cny100019x82x1.htm   \n",
      "4       归途有风  归途有风   https://mojim.com/cny100019x82x1.htm   \n",
      "...      ...   ...                                    ...   \n",
      "104659   致青春    暂存  https://mojim.com/cny100019x58x15.htm   \n",
      "104660   致青春    暂存  https://mojim.com/cny100019x58x15.htm   \n",
      "104661   致青春    暂存  https://mojim.com/cny100019x58x15.htm   \n",
      "104662   致青春    暂存  https://mojim.com/cny100019x58x15.htm   \n",
      "104663   致青春    暂存  https://mojim.com/cny100019x58x15.htm   \n",
      "\n",
      "                                                    Chunk  \n",
      "0       \\n王菲\\n归途有风\\n电影 万里归途 主题曲\\n作词：唐恬@勇士音乐\\n作曲：钱雷@勇士音...  \n",
      "1       才可明白 为何而来\\n要 放开过 勿放的手\\n要 千山万水 懂得泪流\\n要风起 要别离 要万...  \n",
      "2       让它告诉我\\n抉择多难 都已做过\\n不问得失 无悔对错\\n让月光 带我回家\\n让来路 带我回...  \n",
      "3       更多更详尽歌词 在 ※ Mojim.com　魔镜歌词网 \\n门背后 是谁呢 拥抱着 你的噩梦...  \n",
      "4       该我赴的约 都已赴过\\n不问得失 无悔对错\\n让月光 带我回家 牵着我的手\\n让来路 带我回...  \n",
      "...                                                   ...  \n",
      "104659  你闪烁的眼　像脆弱的信念\\n贪恋的岁月　被无情偿还\\n骄纵的心性　已烟消云散\\n疯了　累了　...  \n",
      "104660  良辰美景奈何天　为谁辛苦为谁甜\\n这年华青涩逝去　却别有洞天\\n良辰美景奈何天　为谁辛苦为谁...  \n",
      "104661  [00:02:00]致青春\\n[00:03:00]作词：李樯 作曲：窦鹏\\n[00:04:0...  \n",
      "104662  漫长的告别是青春盛宴\\n我冬夜的手像滚烫的誓言\\n你闪烁的眼像脆弱的信念\\n贪恋的岁月被无情...  \n",
      "104663  这年华青涩逝去\\n却别有洞天\\n良辰美景奈何天\\n为谁辛苦为谁甜\\n这年华青涩逝去\\n明白了...  \n",
      "\n",
      "[104664 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "min_chunk_size = 100\n",
    "new_df = pd.DataFrame(columns=[\"Title\", \"Album\", \"URL\",\"Chunk\"])\n",
    "for index, row in tmp.iterrows():\n",
    "    # split the text in the current row into chunks while respecting the newline characters\n",
    "    chunks = []\n",
    "    for line in row[\"Lyrics\"].split(\"\\n\"):\n",
    "        if len(line) >= min_chunk_size:\n",
    "            chunks.append(line)\n",
    "        else:\n",
    "            merged_chunk = line\n",
    "            for next_line in row[\"Lyrics\"][len(line)+1:].split(\"\\n\"):\n",
    "                if len(merged_chunk) + len(next_line) + 1 < min_chunk_size:\n",
    "                    merged_chunk += \"\\n\" + next_line\n",
    "                else:\n",
    "                    chunks.append(merged_chunk)\n",
    "                    merged_chunk = next_line\n",
    "            chunks.append(merged_chunk)\n",
    "    # create a new dataframe with the resulting chunks and metadata\n",
    "    chunk_df = pd.DataFrame({\n",
    "        \"Title\": [row[\"Title\"]] * len(chunks),\n",
    "        \"URL\": [row[\"URL\"]] * len(chunks),\n",
    "        \"Album\": [row[\"Album Title\"]] * len(chunks),\n",
    "        \"Chunk\": chunks\n",
    "    })\n",
    "    new_df = pd.concat([new_df, chunk_df], ignore_index=True)\n",
    "\n",
    "# display the resulting dataframe\n",
    "print(new_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = CSVLoader(file_path=\"lyrics_wf.csv\", source_column=\"Lyrics\")\n",
    "# loader = DataFrameLoader(new, page_content_column='lyrics')\n",
    "loader = DataFrameLoader(new_df, page_content_column='Chunk')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_API_KEY = os.getenv('COHERE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for CohereEmbeddings\n__root__\n  Did not find cohere_api_key, please add an environment variable `COHERE_API_KEY` which contains it, or pass  `cohere_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Split documents into smaller chunks\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# texts = text_splitter.split_documents(data)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[39m# Initialize OpenAI embeddings\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# embeddings_model = OpenAIEmbeddings()\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcohere\u001b[39;00m \u001b[39mimport\u001b[39;00m CohereEmbeddings\n\u001b[0;32m---> 10\u001b[0m embeddings_model \u001b[39m=\u001b[39m CohereEmbeddings(model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39membed-english-v2.0\u001b[39;49m\u001b[39m\"\u001b[39;49m, cohere_api_key\u001b[39m=\u001b[39;49mCOHERE_API_KEY)\n\u001b[1;32m     11\u001b[0m vectorstore \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39mfrom_documents(data, embeddings_model, persist_directory\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./chroma_db\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m vectorstore\u001b[39m.\u001b[39mpersist()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for CohereEmbeddings\n__root__\n  Did not find cohere_api_key, please add an environment variable `COHERE_API_KEY` which contains it, or pass  `cohere_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "# Split documents into smaller chunks\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "# texts = text_splitter.split_documents(data)\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "# embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "\n",
    "embeddings_model = CohereEmbeddings(model=\"embed-english-v2.0\", cohere_api_key=COHERE_API_KEY)\n",
    "vectorstore = Chroma.from_documents(data, embeddings_model, persist_directory=\"./chroma_db\")\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0), vectorstore.as_retriever(), memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstore.as_retriever()\n",
    "lyrics = retriever.get_relevant_documents(\n",
    "    query=\"今天好开心\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~而我将爱你所爱的人间~\n",
      "～愿你所愿的笑颜~\n",
      "~你的手我蹒跚在牵~\n",
      "~请带~我去~明天~～\n",
      "~如果说你曾苦过我的甜~\n",
      "～我愿活成你~的愿~\n",
      "~愿不枉啊愿勇往啊~\n",
      "~这盛世每~一天～～～\n"
     ]
    }
   ],
   "source": [
    "print(lyrics[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无妄的多情 不忘也多余 不如不散不聚\n",
      "相爱无痕迹 相忘得无忧无虑\n",
      "伤害无痕迹 痛苦得无忧无虑\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lyrics = retriever.get_relevant_documents(\n",
    "    query=\"爱上了不该爱的人，又离不开\"\n",
    ")\n",
    "print(lyrics[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = retriever.get_relevant_documents(\n",
    "    query=\"爱上了不该爱的人，又离不开\"\n",
    ")\n",
    "print(lyrics[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'偶遇'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics[0].metadata['Title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get spotify link for the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import os\n",
    "\n",
    "# set up the Spotify API client\n",
    "client_id = os.getenv(\"SPOTIPY_CLIENT_ID\")\n",
    "client_secret = os.getenv(\"SPOTIPY_CLIENT_SECRET\")\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "def get_spotify_link(lyrics):\n",
    "    song_name = lyrics[0].metadata['Title']\n",
    "    singer_name = \"王菲\"\n",
    "    results = sp.search(q=song_name + \" \" + singer_name, type=\"track\")\n",
    "\n",
    "    # extract the Spotify link to the first result\n",
    "    if len(results[\"tracks\"][\"items\"]) > 0:\n",
    "        song_link = results[\"tracks\"][\"items\"][0][\"external_urls\"][\"spotify\"]\n",
    "        return song_link\n",
    "    else:\n",
    "        return \"No results found for song name: \" + song_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_results(query):\n",
    "    lyrics = retriever.get_relevant_documents(query=query)\n",
    "    link = get_spotify_link(lyrics)\n",
    "    return(lyrics[0].page_content, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('~山河无恙～~烟火寻常～\\n~可是你如愿的眺望～\\n~孩子们啊～~安睡梦乡～\\n~像你深爱的~那样～～～\\n～◆☆◇~而我将\\n梦你所梦的团圆～\\n愿你所愿的永~远～\\n走你所走的长~路~\\n~这样的爱~你啊～',\n",
       " 'https://open.spotify.com/track/4x9retP0JqKa35zZZhNhNS')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chatbot_results(\"爱上了不该爱的人，又离不开\")\n",
    "chatbot_results(\"旋转木马好玩吗\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
